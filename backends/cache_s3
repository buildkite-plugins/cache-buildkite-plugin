#!/bin/bash

if [ -z "${BUILDKITE_PLUGIN_S3_CACHE_BUCKET}" ]; then
  echo '+++ ðŸš¨ Missing S3 bucket configuration'
  exit 1
fi

build_key() {
  if [ -n "${BUILDKITE_PLUGIN_S3_CACHE_PREFIX}" ]; then
    echo "${BUILDKITE_PLUGIN_S3_CACHE_PREFIX}/${1}"
  else
    echo "$1"
  fi
}

aws_cmd() {
  aws_cmd=(aws)

  if [ -n "${BUILDKITE_PLUGIN_S3_CACHE_ENDPOINT}" ]; then
    aws_cmd+=(--endpoint-url "${BUILDKITE_PLUGIN_S3_CACHE_ENDPOINT}")
  fi

  "${aws_cmd[@]}" "$@"
}

s3_copy() {
  local from="$1"
  local to="$2"
  local use_sync="${3:-true}"
  local options=()

  if [ "${use_sync}" = 'true' ]; then
    options+=(sync)
  else
    options+=(cp)
  fi

  if [ -n "${BUILDKITE_PLUGIN_S3_CACHE_ONLY_SHOW_ERRORS}" ]; then
    options+=(--only-show-errors)
  fi

  aws_cmd s3 "${options[@]}" "${from}" "${to}"
}

s3_listobjects() {
  local prefix="$1"

  result="$(
    aws_cmd s3api list-objects-v2 \
      --bucket "${BUILDKITE_PLUGIN_S3_CACHE_BUCKET}" \
      --prefix "$(build_key "${prefix}")" \
      --max-items 1 \
      --query Contents
  )"

  [ "${result}" != 'null' ]
}

restore_cache() {
  local from="$1"
  local to="$2"
  local sync='false'

  key="$(build_key "${from}")"

  # if the object does not exist, assume it is a folder so use sync
  if ! aws_cmd s3api head-object --bucket "${BUILDKITE_PLUGIN_S3_CACHE_BUCKET}" --key "${key}"; then
    sync=true
  fi

  # can not use sync as it may be a single file
  s3_copy "s3://${BUILDKITE_PLUGIN_S3_CACHE_BUCKET}/${key}" "${to}" "${sync}"
}

save_cache() {
  local to="$1"
  local from="$2"
  local use_sync='true'
  if [ -f "${from}" ]; then
    use_sync='false'
  fi

  s3_copy "${from}" "s3://${BUILDKITE_PLUGIN_S3_CACHE_BUCKET}/$(build_key "${to}")" "${use_sync}"
}

exists_cache() {
  if [ -z "$1" ]; then exit 1; fi
  s3_listobjects "$1"
}

OPCODE="$1"
shift

if [ "$OPCODE" = 'exists' ]; then
  exists_cache "$@"
elif [ "$OPCODE" = 'get' ]; then
  restore_cache "$@"
elif [ "$OPCODE" = 'save' ]; then
  save_cache "$@"
else
  exit 255
fi
